{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating Table to Scorecard\n",
    "**Authors**: Vinay Wunnava\n",
    "\n",
    "In this tutorial, you are going to learn how to take a rating table from a `Generalized Additive 2 Model`, also known as `GA2M` and transform it into a scorecard.\n",
    "\n",
    "**There are a few things that you need for this exercise:**\n",
    "\n",
    "1. Your DataRobot API Key\n",
    "2. A trained `Generalized Additive 2 Model` (on any project, with any dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datarobot as dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DataRobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datarobot.rest.RESTClientObject at 0x7f85815e4d60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.Client(token = 'YOUR_API_TOKEN',\n",
    "          endpoint = 'YOUR_ENDPOINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Project and Model ID's.\n",
    "\n",
    "The project and model ID's can be found in the url (when you use the UI to navigate). Make sure that the GA2M model does not have **any text features as input**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = 'YOUR_PROJECT_ID'\n",
    "mid = 'YOUR_MODEL_ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions that download and transform the rating table to scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_rating_table(pid, mid):\n",
    "    \"\"\" Download the rating table corresponding to the pid and mid\n",
    "    \"\"\"\n",
    "    project = dr.Project.get(pid)\n",
    "    rating_tables = rating_tables = project.get_rating_tables()\n",
    "    rating_table = [rt for rt in rating_tables if rt.model_id == mid][0]\n",
    "    filepath = './my_rating_table_' + mid + '.csv'\n",
    "    rating_table.download('./my_rating_table_' + mid + '.csv')\n",
    "    return filepath\n",
    "\n",
    "def csv_after_emptylines(filepath, bl_group_n=1, dtype=str):\n",
    "    \"\"\" Read a .CSV into a Pandas DataFrame, but only after at least one blank line has been skipped.\n",
    "    bl_group_n is the expected number of distinct blocks of blank lines (of any number of rows each) to skip before reading data.\n",
    "    NB: E.g. pd.read_csv(filepath, skiprows=[0, 1, 2]) works if you know the number of rows to be skipped. Use this function if you have a variable / unknown number of filled rows (to be skipped / ignored) before the empty rows.\n",
    "    \"\"\"\n",
    "    with open(filepath, newline='') as f:\n",
    "        blank_lines = 0\n",
    "        bl_groups = 0\n",
    "        contents = []\n",
    "        headers = None\n",
    "        r = csv.reader(f)\n",
    "        for i, l in enumerate(r):\n",
    "            if bl_groups < bl_group_n:\n",
    "                if not l:\n",
    "                    blank_lines += 1\n",
    "                    continue\n",
    "                if blank_lines == 0:\n",
    "                    continue\n",
    "                bl_groups += 1\n",
    "                blank_lines = 0\n",
    "                headers = l\n",
    "                continue\n",
    "            contents.append(l)\n",
    "        return pd.DataFrame(data=contents, columns=headers, dtype=dtype)\n",
    "\n",
    "def csv_until_emptyline(filepath, dtype=str):\n",
    "    \"\"\" Read a .CSV into a Pandas DataFrame until a blank line is found, then stop.\n",
    "    \"\"\"\n",
    "    with open(filepath, newline='') as f:\n",
    "        contents = []\n",
    "        r = csv.reader(f)\n",
    "        for i, l in enumerate(r):\n",
    "            if not l:\n",
    "                break\n",
    "            if i == 0:\n",
    "                headers = l\n",
    "                continue\n",
    "            contents.append(l)\n",
    "        return pd.DataFrame(data=contents)\n",
    "\n",
    "def extract_intercept(filepath):\n",
    "    \"\"\" Read a .CSV into a Pandas DataFrame until a blank line is found, then stop.\n",
    "        Extract intercept value and return it\n",
    "    \"\"\" \n",
    "    df = csv_until_emptyline(filepath)\n",
    "    df.rename(columns={df.columns[0]: \"raw\" }, inplace = True)\n",
    "    df[['name','value']] = df['raw'].str.split(\":\",expand=True)\n",
    "    intercept = pd.to_numeric(df.loc[df.name == 'Intercept','value'].values[0])\n",
    "    return intercept\n",
    "\n",
    "def invert_coefficients(intercept, rating_table):\n",
    "    \"\"\" Inverting the sign of intercept and all the coefficients - this is to ensure that the high risk people are given low scores\n",
    "        Mathematically, we are modelling log of odds and the riskier profiles have high probability\n",
    "        When we negate the coefficients, it will mean the log of odds of non-risky profiles (- log(p/1-p) = log(1-p/p))\n",
    "    \"\"\"\n",
    "    intercept = - intercept\n",
    "    rating_table.loc[:,'Coefficient'] = - rating_table['Coefficient'].astype(float)\n",
    "    return intercept, rating_table\n",
    "\n",
    "def convert_rating_table_to_scores(intercept, rating_table, min_score=300, max_score=850):\n",
    "    rating_table['Rel_Coefficient'] = rating_table['Coefficient']\n",
    "    baseline = intercept\n",
    "    min_sum_coef = 0\n",
    "    max_sum_coef = 0\n",
    "    for feat in rating_table['Feature Name'].unique():\n",
    "        min_feat_coef = rating_table.loc[rating_table['Feature Name'] == feat]['Coefficient'].min()\n",
    "        print('Minimum coefficient for feature ' + feat + ' ' + str(min_feat_coef))\n",
    "        rating_table.loc[rating_table['Feature Name'] == feat,'Rel_Coefficient'] = rating_table['Coefficient'] - min_feat_coef\n",
    "        baseline += min_feat_coef\n",
    "        min_sum_coef = min_sum_coef + rating_table.loc[rating_table['Feature Name'] == feat]['Rel_Coefficient'].min()\n",
    "        max_sum_coef = max_sum_coef + rating_table.loc[rating_table['Feature Name'] == feat]['Rel_Coefficient'].max()\n",
    "\n",
    "    min_sum_coef = min_sum_coef + baseline\n",
    "    max_sum_coef = max_sum_coef + baseline\n",
    "    \n",
    "    rating_table.loc[:,'Variable Score'] = rating_table['Rel_Coefficient']*((max_score-min_score)/(max_sum_coef - min_sum_coef))\n",
    "    baseline_score = (((baseline-min_sum_coef)/(max_sum_coef-min_sum_coef))*(max_score-min_score))+min_score\n",
    "    \n",
    "    return baseline_score, rating_table.drop(columns=['Coefficient','Rel_Coefficient'])\n",
    "\n",
    "def get_scorecard(pid,mid, min_score=300, max_score=850):\n",
    "    \"\"\" Download rating table for a particular pid and mid and return scorecard\n",
    "    \"\"\"\n",
    "    filepath = download_rating_table(pid,mid)    \n",
    "    rating_table_raw = csv_after_emptylines(filepath)\n",
    "    intercept_raw = extract_intercept(filepath)\n",
    "    intercept, rating_table = invert_coefficients(intercept_raw, rating_table_raw)\n",
    "    intercept_score, scorecard = convert_rating_table_to_scores(intercept, rating_table, min_score, max_score)\n",
    "    \n",
    "    return intercept_score, scorecard",
    "\n",
    "def get_score_from_prob(prob, min_score, max_score, min_sum_coef, max_sum_coef):\n",
    "    \"\"\" Get score for a particular probability and return score using the scorecard metrics - useful for threshold\n",
    "    \"\"\"\n",
    "    log_odds = np.log(prob/(1-prob))\n",
    "    score = (((log_odds-min_sum_coef)/(max_sum_coef-min_sum_coef))*(max_score-min_score))+min_score\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Scorecard and Intercept Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum coefficient for feature addr_state -0.2785427564480061\n",
      "Minimum coefficient for feature annual_inc -0.45013078726639455\n",
      "Minimum coefficient for feature delinq_2yrs -0.2776783526503624\n",
      "Minimum coefficient for feature desc -0.0945789794721339\n",
      "Minimum coefficient for feature dti -0.04247463282234684\n",
      "Minimum coefficient for feature earliest_cr_line (Day of Week) -0.48158802883360646\n",
      "Minimum coefficient for feature earliest_cr_line (Month) -0.046347103102299385\n",
      "Minimum coefficient for feature earliest_cr_line (Year) -0.037238379052665034\n",
      "Minimum coefficient for feature emp_length -0.19705440726302845\n",
      "Minimum coefficient for feature emp_title -0.15997129068918214\n",
      "Minimum coefficient for feature funded_amnt -0.08483731228497265\n",
      "Minimum coefficient for feature grade -0.14898665490589103\n",
      "Minimum coefficient for feature home_ownership -0.006745090976323531\n",
      "Minimum coefficient for feature inq_last_6mths -0.19540746068248277\n",
      "Minimum coefficient for feature installment -0.10691166175018307\n",
      "Minimum coefficient for feature int_rate -0.8424409100306465\n",
      "Minimum coefficient for feature loan_amnt -0.11865405012795785\n",
      "Minimum coefficient for feature mths_since_last_delinq -0.016831067654010254\n",
      "Minimum coefficient for feature mths_since_last_record -0.3579067293875854\n",
      "Minimum coefficient for feature open_acc -0.2424327545475713\n",
      "Minimum coefficient for feature pub_rec -2.7913507366823104e-05\n",
      "Minimum coefficient for feature purpose -0.603214070258125\n",
      "Minimum coefficient for feature revol_bal -0.08709952340862444\n",
      "Minimum coefficient for feature revol_util -0.31345346901801996\n",
      "Minimum coefficient for feature sub_grade -0.4451525319485191\n",
      "Minimum coefficient for feature term -0.31037027122147715\n",
      "Minimum coefficient for feature title -0.16896281377344957\n",
      "Minimum coefficient for feature total_acc -0.03989237009687374\n",
      "Minimum coefficient for feature url -0.03283202149656503\n",
      "Minimum coefficient for feature verification_status -0.045329300359824756\n",
      "Minimum coefficient for feature zip_code -0.34274587576999005\n",
      "Minimum coefficient for feature ( purpose & term ) -0.20326967610714788\n"
     ]
    }
   ],
   "source": [
    "intercept_score, scorecard = get_scorecard(pid,mid, min_score=300, max_score=850)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Feature Strength</th>\n",
       "      <th>Type</th>\n",
       "      <th>Transform1</th>\n",
       "      <th>Value1</th>\n",
       "      <th>Transform2</th>\n",
       "      <th>Value2</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Variable Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>addr_state</td>\n",
       "      <td>0.023231943239473876</td>\n",
       "      <td>CAT</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>'AK'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>addr_state</td>\n",
       "      <td>0.023231943239473876</td>\n",
       "      <td>CAT</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>'AL'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>75.0</td>\n",
       "      <td>10.868938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>addr_state</td>\n",
       "      <td>0.023231943239473876</td>\n",
       "      <td>CAT</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>'AR'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.059049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>addr_state</td>\n",
       "      <td>0.023231943239473876</td>\n",
       "      <td>CAT</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>'AZ'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>137.0</td>\n",
       "      <td>8.894924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>addr_state</td>\n",
       "      <td>0.023231943239473876</td>\n",
       "      <td>CAT</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>'CA'</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1120.0</td>\n",
       "      <td>11.358706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49500</th>\n",
       "      <td>( purpose &amp; term )</td>\n",
       "      <td>0.013551590564601186</td>\n",
       "      <td>2W-INT</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>car</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>36 months</td>\n",
       "      <td>131.0</td>\n",
       "      <td>4.459664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49501</th>\n",
       "      <td>( purpose &amp; term )</td>\n",
       "      <td>0.013551590564601186</td>\n",
       "      <td>2W-INT</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>small_business</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>60 months</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49502</th>\n",
       "      <td>( purpose &amp; term )</td>\n",
       "      <td>0.013551590564601186</td>\n",
       "      <td>2W-INT</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>small_business</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>36 months</td>\n",
       "      <td>212.0</td>\n",
       "      <td>12.036993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49503</th>\n",
       "      <td>( purpose &amp; term )</td>\n",
       "      <td>0.013551590564601186</td>\n",
       "      <td>2W-INT</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>60 months</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9.711552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49504</th>\n",
       "      <td>( purpose &amp; term )</td>\n",
       "      <td>0.013551590564601186</td>\n",
       "      <td>2W-INT</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>One-hot</td>\n",
       "      <td>36 months</td>\n",
       "      <td>281.0</td>\n",
       "      <td>8.324389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49505 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Feature Name      Feature Strength    Type Transform1  \\\n",
       "0              addr_state  0.023231943239473876     CAT    One-hot   \n",
       "1              addr_state  0.023231943239473876     CAT    One-hot   \n",
       "2              addr_state  0.023231943239473876     CAT    One-hot   \n",
       "3              addr_state  0.023231943239473876     CAT    One-hot   \n",
       "4              addr_state  0.023231943239473876     CAT    One-hot   \n",
       "...                   ...                   ...     ...        ...   \n",
       "49500  ( purpose & term )  0.013551590564601186  2W-INT    One-hot   \n",
       "49501  ( purpose & term )  0.013551590564601186  2W-INT    One-hot   \n",
       "49502  ( purpose & term )  0.013551590564601186  2W-INT    One-hot   \n",
       "49503  ( purpose & term )  0.013551590564601186  2W-INT    One-hot   \n",
       "49504  ( purpose & term )  0.013551590564601186  2W-INT    One-hot   \n",
       "\n",
       "               Value1 Transform2      Value2  Weight  Variable Score  \n",
       "0                'AK'                           19.0        0.000000  \n",
       "1                'AL'                           75.0       10.868938  \n",
       "2                'AR'                           32.0       10.059049  \n",
       "3                'AZ'                          137.0        8.894924  \n",
       "4                'CA'                         1120.0       11.358706  \n",
       "...               ...        ...         ...     ...             ...  \n",
       "49500             car    One-hot   36 months   131.0        4.459664  \n",
       "49501  small_business    One-hot   60 months    86.0        0.000000  \n",
       "49502  small_business    One-hot   36 months   212.0       12.036993  \n",
       "49503  major_purchase    One-hot   60 months    60.0        9.711552  \n",
       "49504  major_purchase    One-hot   36 months   281.0        8.324389  \n",
       "\n",
       "[49505 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(intercept_score)\n",
    "scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
